{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "model = tf.keras.models.load_model('../model/twitter-spam')\n",
    "model.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-11-07 00:44:49.129692: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:29:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2021-11-07 00:44:49.168520: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:29:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2021-11-07 00:44:49.168965: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:29:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2021-11-07 00:44:49.169630: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-07 00:44:49.171573: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:29:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2021-11-07 00:44:49.171970: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:29:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2021-11-07 00:44:49.172368: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:29:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2021-11-07 00:44:49.781152: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:29:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2021-11-07 00:44:49.781576: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:29:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2021-11-07 00:44:49.781590: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1594] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2021-11-07 00:44:49.781986: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:29:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2021-11-07 00:44:49.782026: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1267 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660, pci bus id: 0000:29:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 75, 12)            265884    \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 256)               275456    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 541,597\n",
      "Trainable params: 541,597\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "squid_tweets = pd.read_json('../dataset/squid-tweets/squid_tweets.json').rename(columns={0: 'tweets'})"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "squid_tweets['tweets']"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0       #BTS, #TXT, And \"#SquidGame\" Nominated For 202...\n",
       "1       tim pool watched squid game and somehow missed...\n",
       "2              Squid Game is short for Squidward’s Gambit\n",
       "3       Having tons of money doesn’t mean anything if ...\n",
       "4       Squid game\\n\\nBAZINGA MV BUKAS NA\\n@SB19Offici...\n",
       "                              ...                        \n",
       "1019                   Squid game https://t.co/8M8al6iWgb\n",
       "1020       I gave squid game a shot and it’s pretty good.\n",
       "1021    OMG this last ass scene from Squid Game is dra...\n",
       "1022    @allkpopBuzz @allkpop At least Lebron watched ...\n",
       "1023                      WHERE IS MY SQUID GAME COSTUME?\n",
       "Name: tweets, Length: 1024, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Load tokenizer\n",
    "import pickle\n",
    "with open('../dataset/basic-tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)\n",
    "\n",
    "squid_seq = tokenizer.texts_to_sequences(squid_tweets['tweets'])\n",
    "squid_pad = tf.keras.preprocessing.sequence.pad_sequences(squid_seq, padding='post', maxlen=71)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "squid_pad[0]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([ 1779, 20445,    12,     1,  3152,    10, 11303,     1,  1410,\n",
       "        1318,     1,  5499,   789,  1760,     1,  5499,   789,  1760,\n",
       "           1,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0],\n",
       "      dtype=int32)"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "squid_tweets['is-spam'] = model.predict(squid_pad)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 75) for input KerasTensor(type_spec=TensorSpec(shape=(None, 75), dtype=tf.float32, name='embedding_4_input'), name='embedding_4_input', description=\"created by layer 'embedding_4_input'\"), but it was called on an input with incompatible shape (32, 71).\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-11-07 00:45:08.873158: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-11-07 00:45:10.022151: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8202\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "model.predict(squid_pad[0:2])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[1.658285e-04],\n",
       "       [9.999201e-01]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "squid_tweets['is-spam'] = [1 if i >= 0.5 else 0 for i in squid_tweets['is-spam']]\n",
    "squid_tweets.tail()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>is-spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>Squid game https://t.co/8M8al6iWgb</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>I gave squid game a shot and it’s pretty good.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>OMG this last ass scene from Squid Game is dra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>@allkpopBuzz @allkpop At least Lebron watched ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023</th>\n",
       "      <td>WHERE IS MY SQUID GAME COSTUME?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 tweets  is-spam\n",
       "1019                 Squid game https://t.co/8M8al6iWgb        1\n",
       "1020     I gave squid game a shot and it’s pretty good.        0\n",
       "1021  OMG this last ass scene from Squid Game is dra...        0\n",
       "1022  @allkpopBuzz @allkpop At least Lebron watched ...        0\n",
       "1023                    WHERE IS MY SQUID GAME COSTUME?        0"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "def pad_seq(text):\n",
    "    global tokenizer\n",
    "    seq = tokenizer.texts_to_sequences([text])\n",
    "    pad = tf.keras.preprocessing.sequence.pad_sequences(seq, padding='post', maxlen=71)\n",
    "    return pad"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "text = 'Hey, do do you know that we are selling new stocks? Go check our website now!'\n",
    "seq = tokenizer.texts_to_sequences([text])[0]\n",
    "pad = \n",
    "seq"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[588, 56, 56, 16, 82, 24, 33, 27, 1192, 41, 4134, 96, 275, 69, 1314, 66]"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "# Cases\n",
    "model.predict(pad_seq('Hey, do you know that we are selling new stocks? Go check our website now!'))\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[1.1930588e-13]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "model.predict(pad_seq('Good Morning'))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[6.09603e-08]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "squid_tweets.to_excel('../dataset/squid-tweets/squid-dataset.xlsx')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.2",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.2 64-bit"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}